{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941b2953",
   "metadata": {},
   "source": [
    "# Configure the Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb73993",
   "metadata": {},
   "source": [
    "This notebook suppose that you have already downloaded a pre-trained network, so that you have run the notebook `download_pretrained_network.ipynb`. Now, we will modify the configuration file in order to train the pre-trained network `EfficientDet D1 640x640`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c42d49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory in models/ to store the training configuration of this model\n",
    "!mkdir training-workspace/models/efficientdet_d1_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0083674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the configuration file into this new folder folder\n",
    "!cp training-workspace/pre-trained-models/efficientdet_d1_coco17_tpu-32/pipeline.config training-workspace/models/efficientdet_d1_v1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9adc30f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model {\r\n",
      "  ssd {\r\n",
      "    num_classes: 90\r\n",
      "    image_resizer {\r\n",
      "      keep_aspect_ratio_resizer {\r\n",
      "        min_dimension: 640\r\n",
      "        max_dimension: 640\r\n",
      "        pad_to_max_dimension: true\r\n",
      "      }\r\n",
      "    }\r\n",
      "    feature_extractor {\r\n",
      "      type: \"ssd_efficientnet-b1_bifpn_keras\"\r\n",
      "      conv_hyperparams {\r\n",
      "        regularizer {\r\n",
      "          l2_regularizer {\r\n",
      "            weight: 3.9999998989515007e-05\r\n",
      "          }\r\n",
      "        }\r\n",
      "        initializer {\r\n",
      "          truncated_normal_initializer {\r\n",
      "            mean: 0.0\r\n",
      "            stddev: 0.029999999329447746\r\n",
      "          }\r\n",
      "        }\r\n",
      "        activation: SWISH\r\n",
      "        batch_norm {\r\n",
      "          decay: 0.9900000095367432\r\n",
      "          scale: true\r\n",
      "          epsilon: 0.0010000000474974513\r\n",
      "        }\r\n",
      "        force_use_bias: true\r\n",
      "      }\r\n",
      "      bifpn {\r\n",
      "        min_level: 3\r\n",
      "        max_level: 7\r\n",
      "        num_iterations: 4\r\n",
      "        num_filters: 88\r\n",
      "      }\r\n",
      "    }\r\n",
      "    box_coder {\r\n",
      "      faster_rcnn_box_coder {\r\n",
      "        y_scale: 1.0\r\n",
      "        x_scale: 1.0\r\n",
      "        height_scale: 1.0\r\n",
      "        width_scale: 1.0\r\n",
      "      }\r\n",
      "    }\r\n",
      "    matcher {\r\n",
      "      argmax_matcher {\r\n",
      "        matched_threshold: 0.5\r\n",
      "        unmatched_threshold: 0.5\r\n",
      "        ignore_thresholds: false\r\n",
      "        negatives_lower_than_unmatched: true\r\n",
      "        force_match_for_each_row: true\r\n",
      "        use_matmul_gather: true\r\n",
      "      }\r\n",
      "    }\r\n",
      "    similarity_calculator {\r\n",
      "      iou_similarity {\r\n",
      "      }\r\n",
      "    }\r\n",
      "    box_predictor {\r\n",
      "      weight_shared_convolutional_box_predictor {\r\n",
      "        conv_hyperparams {\r\n",
      "          regularizer {\r\n",
      "            l2_regularizer {\r\n",
      "              weight: 3.9999998989515007e-05\r\n",
      "            }\r\n",
      "          }\r\n",
      "          initializer {\r\n",
      "            random_normal_initializer {\r\n",
      "              mean: 0.0\r\n",
      "              stddev: 0.009999999776482582\r\n",
      "            }\r\n",
      "          }\r\n",
      "          activation: SWISH\r\n",
      "          batch_norm {\r\n",
      "            decay: 0.9900000095367432\r\n",
      "            scale: true\r\n",
      "            epsilon: 0.0010000000474974513\r\n",
      "          }\r\n",
      "          force_use_bias: true\r\n",
      "        }\r\n",
      "        depth: 88\r\n",
      "        num_layers_before_predictor: 3\r\n",
      "        kernel_size: 3\r\n",
      "        class_prediction_bias_init: -4.599999904632568\r\n",
      "        use_depthwise: true\r\n",
      "      }\r\n",
      "    }\r\n",
      "    anchor_generator {\r\n",
      "      multiscale_anchor_generator {\r\n",
      "        min_level: 3\r\n",
      "        max_level: 7\r\n",
      "        anchor_scale: 4.0\r\n",
      "        aspect_ratios: 1.0\r\n",
      "        aspect_ratios: 2.0\r\n",
      "        aspect_ratios: 0.5\r\n",
      "        scales_per_octave: 3\r\n",
      "      }\r\n",
      "    }\r\n",
      "    post_processing {\r\n",
      "      batch_non_max_suppression {\r\n",
      "        score_threshold: 9.99999993922529e-09\r\n",
      "        iou_threshold: 0.5\r\n",
      "        max_detections_per_class: 100\r\n",
      "        max_total_detections: 100\r\n",
      "      }\r\n",
      "      score_converter: SIGMOID\r\n",
      "    }\r\n",
      "    normalize_loss_by_num_matches: true\r\n",
      "    loss {\r\n",
      "      localization_loss {\r\n",
      "        weighted_smooth_l1 {\r\n",
      "        }\r\n",
      "      }\r\n",
      "      classification_loss {\r\n",
      "        weighted_sigmoid_focal {\r\n",
      "          gamma: 1.5\r\n",
      "          alpha: 0.25\r\n",
      "        }\r\n",
      "      }\r\n",
      "      classification_weight: 1.0\r\n",
      "      localization_weight: 1.0\r\n",
      "    }\r\n",
      "    encode_background_as_zeros: true\r\n",
      "    normalize_loc_loss_by_codesize: true\r\n",
      "    inplace_batchnorm_update: true\r\n",
      "    freeze_batchnorm: false\r\n",
      "    add_background_class: false\r\n",
      "  }\r\n",
      "}\r\n",
      "train_config {\r\n",
      "  batch_size: 128\r\n",
      "  data_augmentation_options {\r\n",
      "    random_horizontal_flip {\r\n",
      "    }\r\n",
      "  }\r\n",
      "  data_augmentation_options {\r\n",
      "    random_scale_crop_and_pad_to_square {\r\n",
      "      output_size: 640\r\n",
      "      scale_min: 0.10000000149011612\r\n",
      "      scale_max: 2.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  sync_replicas: true\r\n",
      "  optimizer {\r\n",
      "    momentum_optimizer {\r\n",
      "      learning_rate {\r\n",
      "        cosine_decay_learning_rate {\r\n",
      "          learning_rate_base: 0.07999999821186066\r\n",
      "          total_steps: 300000\r\n",
      "          warmup_learning_rate: 0.0010000000474974513\r\n",
      "          warmup_steps: 2500\r\n",
      "        }\r\n",
      "      }\r\n",
      "      momentum_optimizer_value: 0.8999999761581421\r\n",
      "    }\r\n",
      "    use_moving_average: false\r\n",
      "  }\r\n",
      "  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\r\n",
      "  num_steps: 300000\r\n",
      "  startup_delay_steps: 0.0\r\n",
      "  replicas_to_aggregate: 8\r\n",
      "  max_number_of_boxes: 100\r\n",
      "  unpad_groundtruth_tensors: false\r\n",
      "  fine_tune_checkpoint_type: \"classification\"\r\n",
      "  use_bfloat16: true\r\n",
      "  fine_tune_checkpoint_version: V2\r\n",
      "}\r\n",
      "train_input_reader: {\r\n",
      "  label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"PATH_TO_BE_CONFIGURED/train2017-?????-of-00256.tfrecord\"\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "eval_config: {\r\n",
      "  metrics_set: \"coco_detection_metrics\"\r\n",
      "  use_moving_averages: false\r\n",
      "  batch_size: 1;\r\n",
      "}\r\n",
      "\r\n",
      "eval_input_reader: {\r\n",
      "  label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\r\n",
      "  shuffle: false\r\n",
      "  num_epochs: 1\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# Display the current configuration file\n",
    "!cat training-workspace/models/efficientdet_d1_v1/pipeline.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e3720",
   "metadata": {},
   "source": [
    "So we will modify this configuration file to make it compatible with our project. TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c717363",
   "metadata": {},
   "source": [
    "Changed:\n",
    "* num_classes set to 1\n",
    "* batch_size set to 32\n",
    "* Added some data augmentation options (see below) \n",
    "* Changed path of fine_tune_checkpoint to the correct path\n",
    "* Changed fine_tune_checkpoint_type from classification to detection since we want to be training the full detection model\n",
    "* Changed use_bfloat16 to false as we are not training on a TPU but a GPU\n",
    "* Changed label_map_path to the correct path of the label map for training\n",
    "* Changed input_path for training to the training TFRecord file\n",
    "* Changed label_map_path to the correct path of the label map for evaluation\n",
    "* Changed input_path for evaluation to the evaluation TFRecord file\n",
    "\n",
    "Data augmentation:\n",
    "* **random_scale_crop_and_pad_to_square**: Randomly scale, crop, and then pad an image to fixed square dimensions. The method sample a random_scale factor from a uniform distribution between scale_min and scale_max, and then resizes the image such that its maximum dimension is (output_size * random_scale). Then a square output_size crop is extracted from the resized image. Lastly, the cropped region is padded to the desired square output_size by filling the empty values with zeros.\n",
    "* **random_horizontal_flip**: Randomly flips the image and detections horizontally, with a probability p.\n",
    "* **random_distort_color**: Randomly distorts color using a combination of brightness, hue, contrast and\n",
    "  saturation changes. Makes sure the output image is still between 0 and 255. With parameter color_ordering=1, the \n",
    "  sequence of adjustment performed is :\n",
    "  * randomly adjusting brightness\n",
    "  * randomly adjusting contrast\n",
    "  * randomly adjusting saturation \n",
    "  * randomly adjusting hue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9284a67b",
   "metadata": {},
   "source": [
    "Manually write the configuration file with the desired modifications:\n",
    "```py\n",
    "model {\n",
    "  ssd {\n",
    "    num_classes: 1 \n",
    "    image_resizer {\n",
    "      keep_aspect_ratio_resizer {\n",
    "        min_dimension: 640\n",
    "        max_dimension: 640\n",
    "        pad_to_max_dimension: true\n",
    "      }\n",
    "    }\n",
    "    feature_extractor {\n",
    "      type: \"ssd_efficientnet-b1_bifpn_keras\"\n",
    "      conv_hyperparams {\n",
    "        regularizer {\n",
    "          l2_regularizer {\n",
    "            weight: 3.9999998989515007e-05\n",
    "          }\n",
    "        }\n",
    "        initializer {\n",
    "          truncated_normal_initializer {\n",
    "            mean: 0.0\n",
    "            stddev: 0.029999999329447746\n",
    "          }\n",
    "        }\n",
    "        activation: SWISH\n",
    "        batch_norm {\n",
    "          decay: 0.9900000095367432\n",
    "          scale: true\n",
    "          epsilon: 0.0010000000474974513\n",
    "        }\n",
    "        force_use_bias: true\n",
    "      }\n",
    "      bifpn {\n",
    "        min_level: 3\n",
    "        max_level: 7\n",
    "        num_iterations: 4\n",
    "        num_filters: 88\n",
    "      }\n",
    "    }\n",
    "    box_coder {\n",
    "      faster_rcnn_box_coder {\n",
    "        y_scale: 1.0\n",
    "        x_scale: 1.0\n",
    "        height_scale: 1.0\n",
    "        width_scale: 1.0\n",
    "      }\n",
    "    }\n",
    "    matcher {\n",
    "      argmax_matcher {\n",
    "        matched_threshold: 0.5\n",
    "        unmatched_threshold: 0.5\n",
    "        ignore_thresholds: false\n",
    "        negatives_lower_than_unmatched: true\n",
    "        force_match_for_each_row: true\n",
    "        use_matmul_gather: true\n",
    "      }\n",
    "    }\n",
    "    similarity_calculator {\n",
    "      iou_similarity {\n",
    "      }\n",
    "    }\n",
    "    box_predictor {\n",
    "      weight_shared_convolutional_box_predictor {\n",
    "        conv_hyperparams {\n",
    "          regularizer {\n",
    "            l2_regularizer {\n",
    "              weight: 3.9999998989515007e-05\n",
    "            }\n",
    "          }\n",
    "          initializer {\n",
    "            random_normal_initializer {\n",
    "              mean: 0.0\n",
    "              stddev: 0.009999999776482582\n",
    "            }\n",
    "          }\n",
    "          activation: SWISH\n",
    "          batch_norm {\n",
    "            decay: 0.9900000095367432\n",
    "            scale: true\n",
    "            epsilon: 0.0010000000474974513\n",
    "          }\n",
    "          force_use_bias: true\n",
    "        }\n",
    "        depth: 88\n",
    "        num_layers_before_predictor: 3\n",
    "        kernel_size: 3\n",
    "        class_prediction_bias_init: -4.599999904632568\n",
    "        use_depthwise: true\n",
    "      }\n",
    "    }\n",
    "    anchor_generator {\n",
    "      multiscale_anchor_generator {\n",
    "        min_level: 3\n",
    "        max_level: 7\n",
    "        anchor_scale: 4.0\n",
    "        aspect_ratios: 1.0\n",
    "        aspect_ratios: 2.0\n",
    "        aspect_ratios: 0.5\n",
    "        scales_per_octave: 3\n",
    "      }\n",
    "    }\n",
    "    post_processing {\n",
    "      batch_non_max_suppression {\n",
    "        score_threshold: 9.99999993922529e-09\n",
    "        iou_threshold: 0.5\n",
    "        max_detections_per_class: 100\n",
    "        max_total_detections: 100\n",
    "      }\n",
    "      score_converter: SIGMOID\n",
    "    }\n",
    "    normalize_loss_by_num_matches: true\n",
    "    loss {\n",
    "      localization_loss {\n",
    "        weighted_smooth_l1 {\n",
    "        }\n",
    "      }\n",
    "      classification_loss {\n",
    "        weighted_sigmoid_focal {\n",
    "          gamma: 1.5\n",
    "          alpha: 0.25\n",
    "        }\n",
    "      }\n",
    "      classification_weight: 1.0\n",
    "      localization_weight: 1.0\n",
    "    }\n",
    "    encode_background_as_zeros: true\n",
    "    normalize_loc_loss_by_codesize: true\n",
    "    inplace_batchnorm_update: true\n",
    "    freeze_batchnorm: false\n",
    "    add_background_class: false\n",
    "  }\n",
    "}\n",
    "train_config {\n",
    "  batch_size: 32\n",
    "  data_augmentation_options {\n",
    "    random_horizontal_flip {\n",
    "      probability: 0.3\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    random_scale_crop_and_pad_to_square {\n",
    "      output_size: 640\n",
    "      scale_min: 0.1\n",
    "      scale_max: 2.0\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    random_distort_color {\n",
    "      color_ordering: 1\n",
    "    }\n",
    "  }\n",
    "  sync_replicas: true\n",
    "  optimizer {\n",
    "    momentum_optimizer {\n",
    "      learning_rate {\n",
    "        cosine_decay_learning_rate {\n",
    "          learning_rate_base: 0.07999999821186066\n",
    "          total_steps: 300000\n",
    "          warmup_learning_rate: 0.0010000000474974513\n",
    "          warmup_steps: 2500\n",
    "        }\n",
    "      }\n",
    "      momentum_optimizer_value: 0.8999999761581421\n",
    "    }\n",
    "    use_moving_average: false\n",
    "  }\n",
    "  fine_tune_checkpoint: \"pre-trained-models/efficientdet_d1_coco17_tpu-32/checkpoint/ckpt-0.index\"\n",
    "  num_steps: 300000\n",
    "  startup_delay_steps: 0.0\n",
    "  replicas_to_aggregate: 8\n",
    "  max_number_of_boxes: 100\n",
    "  unpad_groundtruth_tensors: false\n",
    "  fine_tune_checkpoint_type: \"detection\"\n",
    "  use_bfloat16: false\n",
    "  fine_tune_checkpoint_version: V2\n",
    "}\n",
    "train_input_reader: {\n",
    "  label_map_path: \"annotations/label_map.pbtxt\"\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"annotations/train.record\"\n",
    "  }\n",
    "}\n",
    "\n",
    "eval_config: {\n",
    "  metrics_set: \"coco_detection_metrics\"\n",
    "  use_moving_averages: false\n",
    "  batch_size: 1;\n",
    "}\n",
    "\n",
    "eval_input_reader: {\n",
    "  label_map_path: \"annotations/label_map.pbtxt\"\n",
    "  shuffle: true\n",
    "  num_epochs: 1\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"annotations/validation.record\"\n",
    "  }\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
