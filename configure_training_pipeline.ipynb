{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941b2953",
   "metadata": {},
   "source": [
    "# Configure the Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb73993",
   "metadata": {},
   "source": [
    "This notebook suppose that you have already downloaded a pre-trained network, so that you have run the notebook `download_pretrained_network.ipynb`. Now, we will modify the configuration file in order to train the pre-trained network `EfficientDet D1 640x640`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c42d49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory in models/ to store the training configuration of this model\n",
    "!mkdir training-workspace/models/efficientdet_d1_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0083674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the configuration file into this new folder folder\n",
    "!cp training-workspace/pre-trained-models/efficientdet_d1_coco17_tpu-32/pipeline.config training-workspace/models/efficientdet_d1_v1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9adc30f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model {\r\n",
      "  ssd {\r\n",
      "    num_classes: 90\r\n",
      "    image_resizer {\r\n",
      "      keep_aspect_ratio_resizer {\r\n",
      "        min_dimension: 640\r\n",
      "        max_dimension: 640\r\n",
      "        pad_to_max_dimension: true\r\n",
      "      }\r\n",
      "    }\r\n",
      "    feature_extractor {\r\n",
      "      type: \"ssd_efficientnet-b1_bifpn_keras\"\r\n",
      "      conv_hyperparams {\r\n",
      "        regularizer {\r\n",
      "          l2_regularizer {\r\n",
      "            weight: 3.9999998989515007e-05\r\n",
      "          }\r\n",
      "        }\r\n",
      "        initializer {\r\n",
      "          truncated_normal_initializer {\r\n",
      "            mean: 0.0\r\n",
      "            stddev: 0.029999999329447746\r\n",
      "          }\r\n",
      "        }\r\n",
      "        activation: SWISH\r\n",
      "        batch_norm {\r\n",
      "          decay: 0.9900000095367432\r\n",
      "          scale: true\r\n",
      "          epsilon: 0.0010000000474974513\r\n",
      "        }\r\n",
      "        force_use_bias: true\r\n",
      "      }\r\n",
      "      bifpn {\r\n",
      "        min_level: 3\r\n",
      "        max_level: 7\r\n",
      "        num_iterations: 4\r\n",
      "        num_filters: 88\r\n",
      "      }\r\n",
      "    }\r\n",
      "    box_coder {\r\n",
      "      faster_rcnn_box_coder {\r\n",
      "        y_scale: 1.0\r\n",
      "        x_scale: 1.0\r\n",
      "        height_scale: 1.0\r\n",
      "        width_scale: 1.0\r\n",
      "      }\r\n",
      "    }\r\n",
      "    matcher {\r\n",
      "      argmax_matcher {\r\n",
      "        matched_threshold: 0.5\r\n",
      "        unmatched_threshold: 0.5\r\n",
      "        ignore_thresholds: false\r\n",
      "        negatives_lower_than_unmatched: true\r\n",
      "        force_match_for_each_row: true\r\n",
      "        use_matmul_gather: true\r\n",
      "      }\r\n",
      "    }\r\n",
      "    similarity_calculator {\r\n",
      "      iou_similarity {\r\n",
      "      }\r\n",
      "    }\r\n",
      "    box_predictor {\r\n",
      "      weight_shared_convolutional_box_predictor {\r\n",
      "        conv_hyperparams {\r\n",
      "          regularizer {\r\n",
      "            l2_regularizer {\r\n",
      "              weight: 3.9999998989515007e-05\r\n",
      "            }\r\n",
      "          }\r\n",
      "          initializer {\r\n",
      "            random_normal_initializer {\r\n",
      "              mean: 0.0\r\n",
      "              stddev: 0.009999999776482582\r\n",
      "            }\r\n",
      "          }\r\n",
      "          activation: SWISH\r\n",
      "          batch_norm {\r\n",
      "            decay: 0.9900000095367432\r\n",
      "            scale: true\r\n",
      "            epsilon: 0.0010000000474974513\r\n",
      "          }\r\n",
      "          force_use_bias: true\r\n",
      "        }\r\n",
      "        depth: 88\r\n",
      "        num_layers_before_predictor: 3\r\n",
      "        kernel_size: 3\r\n",
      "        class_prediction_bias_init: -4.599999904632568\r\n",
      "        use_depthwise: true\r\n",
      "      }\r\n",
      "    }\r\n",
      "    anchor_generator {\r\n",
      "      multiscale_anchor_generator {\r\n",
      "        min_level: 3\r\n",
      "        max_level: 7\r\n",
      "        anchor_scale: 4.0\r\n",
      "        aspect_ratios: 1.0\r\n",
      "        aspect_ratios: 2.0\r\n",
      "        aspect_ratios: 0.5\r\n",
      "        scales_per_octave: 3\r\n",
      "      }\r\n",
      "    }\r\n",
      "    post_processing {\r\n",
      "      batch_non_max_suppression {\r\n",
      "        score_threshold: 9.99999993922529e-09\r\n",
      "        iou_threshold: 0.5\r\n",
      "        max_detections_per_class: 100\r\n",
      "        max_total_detections: 100\r\n",
      "      }\r\n",
      "      score_converter: SIGMOID\r\n",
      "    }\r\n",
      "    normalize_loss_by_num_matches: true\r\n",
      "    loss {\r\n",
      "      localization_loss {\r\n",
      "        weighted_smooth_l1 {\r\n",
      "        }\r\n",
      "      }\r\n",
      "      classification_loss {\r\n",
      "        weighted_sigmoid_focal {\r\n",
      "          gamma: 1.5\r\n",
      "          alpha: 0.25\r\n",
      "        }\r\n",
      "      }\r\n",
      "      classification_weight: 1.0\r\n",
      "      localization_weight: 1.0\r\n",
      "    }\r\n",
      "    encode_background_as_zeros: true\r\n",
      "    normalize_loc_loss_by_codesize: true\r\n",
      "    inplace_batchnorm_update: true\r\n",
      "    freeze_batchnorm: false\r\n",
      "    add_background_class: false\r\n",
      "  }\r\n",
      "}\r\n",
      "train_config {\r\n",
      "  batch_size: 128\r\n",
      "  data_augmentation_options {\r\n",
      "    random_horizontal_flip {\r\n",
      "    }\r\n",
      "  }\r\n",
      "  data_augmentation_options {\r\n",
      "    random_scale_crop_and_pad_to_square {\r\n",
      "      output_size: 640\r\n",
      "      scale_min: 0.10000000149011612\r\n",
      "      scale_max: 2.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  sync_replicas: true\r\n",
      "  optimizer {\r\n",
      "    momentum_optimizer {\r\n",
      "      learning_rate {\r\n",
      "        cosine_decay_learning_rate {\r\n",
      "          learning_rate_base: 0.07999999821186066\r\n",
      "          total_steps: 300000\r\n",
      "          warmup_learning_rate: 0.0010000000474974513\r\n",
      "          warmup_steps: 2500\r\n",
      "        }\r\n",
      "      }\r\n",
      "      momentum_optimizer_value: 0.8999999761581421\r\n",
      "    }\r\n",
      "    use_moving_average: false\r\n",
      "  }\r\n",
      "  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\r\n",
      "  num_steps: 300000\r\n",
      "  startup_delay_steps: 0.0\r\n",
      "  replicas_to_aggregate: 8\r\n",
      "  max_number_of_boxes: 100\r\n",
      "  unpad_groundtruth_tensors: false\r\n",
      "  fine_tune_checkpoint_type: \"classification\"\r\n",
      "  use_bfloat16: true\r\n",
      "  fine_tune_checkpoint_version: V2\r\n",
      "}\r\n",
      "train_input_reader: {\r\n",
      "  label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"PATH_TO_BE_CONFIGURED/train2017-?????-of-00256.tfrecord\"\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "eval_config: {\r\n",
      "  metrics_set: \"coco_detection_metrics\"\r\n",
      "  use_moving_averages: false\r\n",
      "  batch_size: 1;\r\n",
      "}\r\n",
      "\r\n",
      "eval_input_reader: {\r\n",
      "  label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\r\n",
      "  shuffle: false\r\n",
      "  num_epochs: 1\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# Display the current configuration file\n",
    "!cat training-workspace/models/efficientdet_d1_v1/pipeline.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e3720",
   "metadata": {},
   "source": [
    "So we modified this configuration file to make it compatible with our project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87494f4",
   "metadata": {},
   "source": [
    "Here is what we changed in this configuration file:\n",
    "* In `model`, we changed `num_classes` to 1 as we only want to predict the cyclists. This corresponds to changing the last dense layer of the neural network with only one neuron.\n",
    "\n",
    "\n",
    "* In `train_config`, we changed the `batch_size` to 3 in order to fit the memory of the GPU used to train the network.\n",
    "* In `train_config`, we added some data augmentation options (see below).\n",
    "* In `train_config`, changed the base learning rate to 0.02 to avoid exploding gradients.\n",
    "* In `train_config`, we changed the path of `fine_tune_checkpoint` to the correct path, so the weights of the model are initialized at the last checkpoint.\n",
    "* In `train_config`, we changed `fine_tune_checkpoint_type` from classification to detection since we want to be training the full detection model and not only the classification part.\n",
    "\n",
    "\n",
    "* In `train_config`, we changed `use_bfloat16` to false as we are not training on a TPU but a GPU.\n",
    "\n",
    "\n",
    "* In `train_input_reader`, we changed `label_map_path` to the correct path of the label map for training.\n",
    "* In `train_input_reader`, we changed `input_path` to the path of the training set so `train.record`.\n",
    "\n",
    "\n",
    "* In `eval_input_reader`, we changed `label_map_path` to the correct path of the label map for evaluation.\n",
    "* In `eval_input_reader`, we changed `input_path` to the path of the validation set so `validation.record`.\n",
    "\n",
    "Data augmentation:\n",
    "* **random_scale_crop_and_pad_to_square**: Randomly scale, crop, and then pad the images to fixed square dimensions. The method sample a random_scale factor from a uniform distribution between scale_min and scale_max, and then resizes the image such that its maximum dimension is (output_size * random_scale). Then a square output_size crop is extracted from the resized image. Lastly, the cropped region is padded to the desired square output_size (640x640 here) by filling the empty values with zeros.\n",
    "* **random_horizontal_flip**: Randomly flips the image and detections horizontally, with a probability p. Here we chose p=0.3, so the probability that an image is horizontally flipped is 30%.\n",
    "* **random_distort_color**: Randomly distorts color in images using a combination of brightness, hue, contrast and\n",
    "  saturation changes. By using the parameter `color_ordering=1`, the sequence of adjustment performed is :\n",
    "  1. randomly adjusting brightness\n",
    "  2. randomly adjusting contrast\n",
    "  3. randomly adjusting saturation \n",
    "  4. randomly adjusting hue.\n",
    "  \n",
    "We choosed to use the random scale,crop and pad to square data augmentation option because during the data exploration phase, we noticed that most of the cyclists were in the center of the image. Thus, to give different examples to the model, this data augmentation option will create other images where the cyclists won't be in the center of the image.\n",
    "\n",
    "We choosed to use the horizontal_flip data augmentation option because this will create more examples to train the network. As the cyclists can come from the left,right or front of the camera, this data augmentation option will help the network to see diverse cases of cyclist positions.\n",
    "\n",
    "We choosed to use the random_distort_color data augmentation option because during the data exploration phase, we noticed that the luminosity of the images are low, with a low contrast and a low saturation. Thus, this data augmentation option will help the network to see other examples with a different brightness, contrast, saturation and hue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d7ac87",
   "metadata": {},
   "source": [
    "Then we manually copied the content of the configuration file in `training-workspace/models/efficientdet_d1_v1/pipeline.config`:\n",
    "```py\n",
    "model {\n",
    "  # Here is the characteristics of the single shot detector\n",
    "  ssd {\n",
    "    # One class to predict\n",
    "    num_classes: 1\n",
    "    # Image resize layer so every images are resized to 640x640\n",
    "    image_resizer {\n",
    "      keep_aspect_ratio_resizer {\n",
    "        min_dimension: 640\n",
    "        max_dimension: 640\n",
    "        pad_to_max_dimension: true\n",
    "      }\n",
    "    }\n",
    "    # Characteristics of the feature extractor \n",
    "    feature_extractor {\n",
    "      type: \"ssd_efficientnet-b1_bifpn_keras\"\n",
    "      conv_hyperparams {\n",
    "        regularizer {\n",
    "          l2_regularizer {\n",
    "            weight: 3.9999998989515007e-05\n",
    "          }\n",
    "        }\n",
    "        initializer {\n",
    "          truncated_normal_initializer {\n",
    "            mean: 0.0\n",
    "            stddev: 0.029999999329447746\n",
    "          }\n",
    "        }\n",
    "        activation: SWISH\n",
    "        batch_norm {\n",
    "          decay: 0.9900000095367432\n",
    "          scale: true\n",
    "          epsilon: 0.0010000000474974513\n",
    "        }\n",
    "        force_use_bias: true\n",
    "      }\n",
    "      bifpn {\n",
    "        min_level: 3\n",
    "        max_level: 7\n",
    "        num_iterations: 4\n",
    "        num_filters: 88\n",
    "      }\n",
    "    }\n",
    "    box_coder {\n",
    "      faster_rcnn_box_coder {\n",
    "        y_scale: 1.0\n",
    "        x_scale: 1.0\n",
    "        height_scale: 1.0\n",
    "        width_scale: 1.0\n",
    "      }\n",
    "    }\n",
    "    matcher {\n",
    "      argmax_matcher {\n",
    "        matched_threshold: 0.5\n",
    "        unmatched_threshold: 0.5\n",
    "        ignore_thresholds: false\n",
    "        negatives_lower_than_unmatched: true\n",
    "        force_match_for_each_row: true\n",
    "        use_matmul_gather: true\n",
    "      }\n",
    "    }\n",
    "    similarity_calculator {\n",
    "      iou_similarity {\n",
    "      }\n",
    "    }\n",
    "    box_predictor {\n",
    "      weight_shared_convolutional_box_predictor {\n",
    "        conv_hyperparams {\n",
    "          regularizer {\n",
    "            l2_regularizer {\n",
    "              weight: 3.9999998989515007e-05\n",
    "            }\n",
    "          }\n",
    "          initializer {\n",
    "            random_normal_initializer {\n",
    "              mean: 0.0\n",
    "              stddev: 0.009999999776482582\n",
    "            }\n",
    "          }\n",
    "          activation: SWISH\n",
    "          batch_norm {\n",
    "            decay: 0.9900000095367432\n",
    "            scale: true\n",
    "            epsilon: 0.0010000000474974513\n",
    "          }\n",
    "          force_use_bias: true\n",
    "        }\n",
    "        depth: 88\n",
    "        num_layers_before_predictor: 3\n",
    "        kernel_size: 3\n",
    "        class_prediction_bias_init: -4.599999904632568\n",
    "        use_depthwise: true\n",
    "      }\n",
    "    }\n",
    "    anchor_generator {\n",
    "      multiscale_anchor_generator {\n",
    "        min_level: 3\n",
    "        max_level: 7\n",
    "        anchor_scale: 4.0\n",
    "        aspect_ratios: 1.0\n",
    "        aspect_ratios: 2.0\n",
    "        aspect_ratios: 0.5\n",
    "        scales_per_octave: 3\n",
    "      }\n",
    "    }\n",
    "    # Use non max suppression to remove the duplicate bounding boxes\n",
    "    post_processing {\n",
    "      batch_non_max_suppression {\n",
    "        score_threshold: 9.99999993922529e-09\n",
    "        iou_threshold: 0.5\n",
    "        max_detections_per_class: 100\n",
    "        max_total_detections: 100\n",
    "      }\n",
    "      score_converter: SIGMOID\n",
    "    }\n",
    "    normalize_loss_by_num_matches: true\n",
    "    loss {\n",
    "      localization_loss {\n",
    "        weighted_smooth_l1 {\n",
    "        }\n",
    "      }\n",
    "      classification_loss {\n",
    "        weighted_sigmoid_focal {\n",
    "          gamma: 1.5\n",
    "          alpha: 0.25\n",
    "        }\n",
    "      }\n",
    "      classification_weight: 1.0\n",
    "      localization_weight: 1.0\n",
    "    }\n",
    "    encode_background_as_zeros: true\n",
    "    normalize_loc_loss_by_codesize: true\n",
    "    inplace_batchnorm_update: true\n",
    "    freeze_batchnorm: false\n",
    "    add_background_class: false\n",
    "  }\n",
    "}\n",
    "train_config {\n",
    "  # Set batch size\n",
    "  batch_size: 3\n",
    "  # Add all the data augmentation in different pipeline\n",
    "  data_augmentation_options {\n",
    "    random_horizontal_flip {\n",
    "      probability: 0.3\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    random_scale_crop_and_pad_to_square {\n",
    "      output_size: 640\n",
    "      scale_min: 0.1\n",
    "      scale_max: 2.0\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    random_distort_color {\n",
    "      color_ordering: 1\n",
    "    }\n",
    "  }\n",
    "  sync_replicas: true\n",
    "  # Set optimizer with a cosine decay so the learning rate get smaller and smaller\n",
    "  optimizer {\n",
    "    momentum_optimizer {\n",
    "      learning_rate {\n",
    "        cosine_decay_learning_rate {\n",
    "          learning_rate_base: 0.02\n",
    "          total_steps: 300000\n",
    "          warmup_learning_rate: 0.0010000000474974513\n",
    "          warmup_steps: 2500\n",
    "        }\n",
    "      }\n",
    "      # use momentup to avoid being stuck on flat regions of the gradient\n",
    "      momentum_optimizer_value: 0.8999999761581421\n",
    "    }\n",
    "    use_moving_average: false\n",
    "  }\n",
    "  fine_tune_checkpoint: \"pre-trained-models/efficientdet_d1_coco17_tpu-32/checkpoint/ckpt-0\"\n",
    "  num_steps: 300000\n",
    "  startup_delay_steps: 0.0\n",
    "  replicas_to_aggregate: 8\n",
    "  max_number_of_boxes: 100\n",
    "  unpad_groundtruth_tensors: false\n",
    "  fine_tune_checkpoint_type: \"detection\"\n",
    "  use_bfloat16: false\n",
    "  fine_tune_checkpoint_version: V2\n",
    "}\n",
    "train_input_reader: {\n",
    "  label_map_path: \"annotations/label_map.pbtxt\"\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"annotations/train.record\"\n",
    "  }\n",
    "}\n",
    "\n",
    "eval_config: {\n",
    "  metrics_set: \"coco_detection_metrics\"\n",
    "  use_moving_averages: false\n",
    "  batch_size: 1;\n",
    "}\n",
    "\n",
    "eval_input_reader: {\n",
    "  label_map_path: \"annotations/label_map.pbtxt\"\n",
    "  shuffle: true\n",
    "  num_epochs: 1\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"annotations/validation.record\"\n",
    "  }\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
